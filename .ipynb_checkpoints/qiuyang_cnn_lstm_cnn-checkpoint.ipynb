{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GrIEHEhAKcZ"
   },
   "source": [
    "Author: Qiu Yang\n",
    "\n",
    "CNN-RNN-CNN\n",
    "\n",
    "**Settings used for current result:**\n",
    "\n",
    "[X, Y, 0/1],  92.1 full image test set, 75.6% (0.5), 81.88(0.7), 86.5(0.9, shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MtsFQfHzulET"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os.path as path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1541669704012,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "ZmsvnbXRulEZ",
    "outputId": "6894e9e6-5ad3-4af3-dd2b-40f5da904f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suS_js-gABnF"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqIfo7oPm20Y"
   },
   "source": [
    "**unpack dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2566,
     "status": "ok",
     "timestamp": 1541669707828,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "jtkWxu9lulEh",
    "outputId": "fd334696-f7f2-4e80-b461-7b8444abf73b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506595 506595\n",
      "126649 126649\n"
     ]
    }
   ],
   "source": [
    "data_path  = 'C:/Users/Persist/Desktop/out_all'\n",
    "with open(path.join(data_path,'train_X'),'rb') as f:\n",
    "    train_X=pickle.load(f)\n",
    "    \n",
    "with open(path.join(data_path,'train_Y'),'rb') as f:\n",
    "    train_Y=pickle.load(f)\n",
    "\n",
    "#test_X_9 contains incomplete image(0.9), premade to free RAM. If no premade files or other incomplete rate, use the create incomplete data functions below\n",
    "with open(path.join(data_path,'test_X_9'),'rb') as f:\n",
    "    test_X=pickle.load(f)\n",
    "    \n",
    "with open(path.join(data_path,'test_Y_9'),'rb') as f:\n",
    "    test_Y=pickle.load(f)\n",
    "\n",
    "print(len(train_X),len(train_Y))\n",
    "\n",
    "print(len(test_X),len(test_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1541669709267,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "aKZzEEoSZPal",
    "outputId": "fdd2c938-a92f-4415-bb10-310ea389754e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "#check classes\n",
    "a = set(train_Y)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kQq4PTdismBO"
   },
   "source": [
    "**A random sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1534,
     "status": "ok",
     "timestamp": 1541572093846,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "1QvGLEOiulEn",
    "outputId": "43eee548-ed32-45e6-b47f-3dc352471c64",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bd08767b8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sketch = random.choice(train_X)\n",
    "for i in range(len(sketch)):\n",
    "    plt.plot(sketch[i][0][:], sketch[i][1][:])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJEk8gg3ASTG"
   },
   "source": [
    "**reformat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16280,
     "status": "ok",
     "timestamp": 1541669731340,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "AsYZrNVwulEt",
    "outputId": "91389cb0-2d1f-418e-fc79-d4d66500d69f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506595\n",
      "30 200\n",
      "27 200\n"
     ]
    }
   ],
   "source": [
    "#use train_X[:n] if you want to sub sample the data for faster run \n",
    "train_sample = np.array(train_X)\n",
    "train_label_sample = np.array(train_Y)\n",
    "test_sample = np.array(test_X)\n",
    "test_label_sample = np.array(test_Y)\n",
    "\n",
    "def get_max_len(sub_sample):\n",
    "    max_stroke_length = 0\n",
    "    max_point_length = 0\n",
    "    for i in range(len(sub_sample)): \n",
    "        if len(sub_sample[i])> max_stroke_length: \n",
    "            max_stroke_length = len(sub_sample[i])\n",
    "        for j in range(len(sub_sample[i])): \n",
    "            if len(sub_sample[i][j][0])> max_point_length:\n",
    "                max_point_length = len(sub_sample[i][j][0])\n",
    "    return max_stroke_length,max_point_length\n",
    "                \n",
    "max_stroke_len,max_point_len = get_max_len(train_sample)    \n",
    "test_max_stroke, test_max_point = get_max_len(test_sample)\n",
    "print (max_stroke_len,max_point_len)\n",
    "print (test_max_stroke,test_max_point)\n",
    "    \n",
    "# no 0 padding (not used, reserved)\n",
    "def process_data(sub_sample, append):\n",
    "    stroke_data = []\n",
    "    point_data = []\n",
    "    for i in range(len(sub_sample)): #image\n",
    "        for j in range(len(sub_sample[i])): #strokes\n",
    "            for k in range(len(sub_sample[i][j][0])): #points\n",
    "                if append:\n",
    "                    if k == len(sub_sample[i][j][0])-1:\n",
    "                        temp2 = [sub_sample[i][j][0][k],sub_sample[i][j][1][k],1]\n",
    "                    else:\n",
    "                        temp2 = [sub_sample[i][j][0][k],sub_sample[i][j][1][k],0]\n",
    "                    point_data.append(temp2)\n",
    "                else:\n",
    "                    temp = [sub_sample[i][j][0][k],sub_sample[i][j][1][k]]\n",
    "                    point_data.append(temp)\n",
    "        stroke_data.append(point_data)\n",
    "        point_data = []\n",
    "            \n",
    "    return stroke_data\n",
    "\n",
    "#train_data = process_data(train_sample, 1)\n",
    "#test_data = process_data(test_sample, 1)\n",
    "\n",
    "# 0 padding\n",
    "def unpack(x,max_strock,max_len):\n",
    "    x_new=torch.zeros(torch.Size([x.shape[0],max_strock,3,max_len]))\n",
    "    for i,item in enumerate(x):\n",
    "        for j,strock in enumerate(item):\n",
    "            strock=torch.Tensor(strock)\n",
    "            x_new[i,j,0,:len(strock[0])]=strock[0]\n",
    "            x_new[i,j,1,:len(strock[0])]=strock[1]\n",
    "            x_new[i,j,2,:len(strock[0])]=0\n",
    "            x_new[i,j,2,len(strock[0])-1]=1\n",
    "    return x_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1541669735895,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "6t9V5ZoNWOZd",
    "outputId": "fa6b344c-b46b-4569-bd79-976c076c1a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506595 0 126649\n",
      "{0, 1, 2, 3, 4} {0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "#string to int label for label classes\n",
    "label_set = set(train_label_sample)\n",
    "label_list = list(label_set)\n",
    "train_label_tensor = []\n",
    "for i in range(len(train_label_sample)):\n",
    "    train_label_tensor.append(label_list.index(train_label_sample[i]))\n",
    "test_label_set = set(test_Y)\n",
    "test_label_list = list(test_label_set)\n",
    "test_label_tensor = []\n",
    "for i in range(len(test_label_sample)):\n",
    "    test_label_tensor.append(test_label_list.index(test_label_sample[i]))  \n",
    "print (len(train_label_tensor),train_label_tensor[0],len(test_label_tensor))\n",
    "print(set(train_label_tensor),set(test_label_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoQvUUnPqhC_"
   },
   "source": [
    "**Create incomplete testset (skip the following 2 sections if testing on complete data, or using pre-made test set for incomplete data)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1541558888708,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "3f4b4MIRqgiw",
    "outputId": "8b301750-0a62-477b-b851-ab5bb05a0499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126649 126649\n",
      "97546 126649\n"
     ]
    }
   ],
   "source": [
    "dup_sample = test_sample.copy()\n",
    "dup_label = test_label_tensor.copy()\n",
    "print(len(dup_sample),len(dup_label))\n",
    "\n",
    "min_num_strokes = 2\n",
    "percentage = 0.5 #change the percentage of reserved stokes here\n",
    "\n",
    "def sample_random_strokes(dataset,labelset,rand,percent): #rand=1: picking storke randomly; rand=0: picking sequentially\n",
    "    new_set = []\n",
    "    new_strokes = []\n",
    "    new_label = []\n",
    "    for i in range(len(dataset)):\n",
    "        if len(dataset[i]) < min_num_strokes:\n",
    "            continue\n",
    "        if rand:\n",
    "            for j in range(int(len(dataset[i])*percent)):                \n",
    "                stroke = dataset[i].pop(random.randrange(len(dataset[i])))\n",
    "                new_strokes.append(stroke)\n",
    "        else:\n",
    "            for j in range(int(len(dataset[i])*percent)):                \n",
    "                stroke = dataset[i][j]\n",
    "                new_strokes.append(stroke) \n",
    "                \n",
    "        new_label.append(labelset[i])        \n",
    "        new_set.append(new_strokes)  \n",
    "        new_strokes = []\n",
    "        \n",
    "    return new_set,new_label\n",
    "\n",
    "a,b= sample_random_strokes(dup_sample,dup_label, 0 ,percentage)\n",
    "print(len(a),len(dup_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2625,
     "status": "ok",
     "timestamp": 1541558894670,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "zQjzfTRRsEli",
    "outputId": "597661ba-b367-4069-beb8-87436bdb81cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 323\n",
      "3920 3920 tensor([[[ 72.,  68.,  69.,  ...,   0.,   0.,   0.],\n",
      "         [ 26.,  23.,  11.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[ 88.,  82.,  79.,  ...,   0.,   0.,   0.],\n",
      "         [  9.,  12.,  18.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[134., 121., 123.,  ...,   0.,   0.,   0.],\n",
      "         [ 29.,  24.,  15.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]])\n"
     ]
    }
   ],
   "source": [
    "#process created incomplete images\n",
    "max_st_len,max_po_len = get_max_len(a)    \n",
    "print (max_st_len,max_po_len)\n",
    "a = np.array(a)\n",
    "\n",
    "incomp_test_data =  unpack(a,max_stroke_len,max_point_len)\n",
    "incomp_test_label = b\n",
    "print(len(incomp_test_data),len(incomp_test_label),incomp_test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5AZJyDtA7UZ"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAwd4QPWbj50"
   },
   "source": [
    "**Model_2: stroke as input unit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wWo_0gr3FK9"
   },
   "outputs": [],
   "source": [
    "batch = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHA03dprbkEv"
   },
   "outputs": [],
   "source": [
    "class lstm_cnn (nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(lstm_cnn, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(3,6,3,padding = 1) #2 output channel for each input channel\n",
    "        self.conv3 =  nn.Conv1d(3,12,3,padding = 1)\n",
    "        self.lstm = nn.LSTM(300, 80) \n",
    "        self.conv2 = nn.Conv1d(1,4,3, padding = 1) #4 channels for 1 h_seq\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.linear = nn.Linear(2400 , 100)\n",
    "        self.output = nn.Linear(100, 5)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim = -1)\n",
    "        \n",
    "    def forward(self, input_data, h_init, c_init ):\n",
    "        temp = self.conv1(input_data)\n",
    "        temp = F.relu(temp)\n",
    "        temp = self.pool(temp)\n",
    "        \n",
    "        temp = self.conv3(temp)\n",
    "        temp = F.relu(temp)\n",
    "        temp = self.pool(temp)\n",
    "        \n",
    "        temp = temp.view(max_stroke_len,-1,300)\n",
    "        h_seq , (h_final,c_final)  =   self.lstm( temp , (h_init,c_init) )\n",
    "        \n",
    "        temp = h_seq.view(-1,1,batch)      \n",
    "        temp = self.conv2(temp)\n",
    "        temp = F.relu(temp)\n",
    "        temp = self.pool(temp)\n",
    "        \n",
    "        #temp = F.dropout(temp,0.4) \n",
    "        \n",
    "        temp = temp.view(batch,-1)\n",
    "        temp = self.linear(temp)\n",
    "        temp = F.relu(temp) \n",
    "        \n",
    "        temp = self.output(temp)\n",
    "        score = self.softmax(temp)\n",
    "        \n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rxaHZ9fhNZw"
   },
   "source": [
    "**Build the net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1541691879780,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "Jio9zcAJulE1",
    "outputId": "cc59a3f9-ff52-4b49-bbe1-d3de9f4e8987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_cnn(\n",
      "  (conv1): Conv1d(3, 6, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv3): Conv1d(3, 12, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (lstm): LSTM(300, 80)\n",
      "  (conv2): Conv1d(1, 4, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=2400, out_features=100, bias=True)\n",
      "  (output): Linear(in_features=100, out_features=5, bias=True)\n",
      "  (softmax): Softmax()\n",
      ")\n",
      "There are 363041 (0.36 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "def display_num_param(net):\n",
    "    nb_param = 0\n",
    "    for param in net.parameters():\n",
    "        nb_param += param.numel()\n",
    "    print('There are {} ({:.2f} million) parameters in this neural network'.format(\n",
    "        nb_param, nb_param/1e6)\n",
    "         )\n",
    "\n",
    "net = lstm_cnn()\n",
    "\n",
    "print(net)\n",
    "\n",
    "display_num_param(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1541691882624,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "Lt68k2gSulE5",
    "outputId": "64e040b0-1c35-406e-dbd7-d1915a4ca529",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0285, -0.0464,  0.0516, -0.0954,  0.0834, -0.0443,  0.0763,  0.0090,\n",
       "          0.0964,  0.0289, -0.0266, -0.0534,  0.0078, -0.0545,  0.0116,  0.0494,\n",
       "         -0.0923,  0.0965, -0.0803,  0.0499,  0.0097, -0.0224,  0.0208, -0.0451,\n",
       "         -0.0956, -0.0696,  0.0366,  0.0409, -0.0980, -0.0641, -0.0936,  0.0690,\n",
       "         -0.0865, -0.0253,  0.0213,  0.0510, -0.0742, -0.0353, -0.0312, -0.0740,\n",
       "          0.0689, -0.0752,  0.0105, -0.0449, -0.0141, -0.0563,  0.0665,  0.0794,\n",
       "         -0.0774, -0.0149,  0.0758, -0.0187, -0.0782,  0.0390, -0.0817,  0.0497,\n",
       "         -0.0450,  0.0730,  0.0428, -0.0081,  0.0781,  0.0209, -0.0647, -0.0835,\n",
       "         -0.0038,  0.0971,  0.0693, -0.0149, -0.0227,  0.0602, -0.0427,  0.0357,\n",
       "          0.0139,  0.0844, -0.0763,  0.0550,  0.0976, -0.0764,  0.0337,  0.0295,\n",
       "         -0.0325, -0.0029, -0.0734,  0.0472,  0.0272, -0.0013, -0.0731,  0.0118,\n",
       "         -0.0646,  0.0871, -0.0416,  0.0732, -0.0531,  0.0804, -0.0296, -0.0420,\n",
       "         -0.0411,  0.0008,  0.0762,  0.0086],\n",
       "        [-0.0931, -0.0658,  0.0402, -0.0812, -0.0860, -0.0552,  0.0347, -0.0200,\n",
       "          0.0098, -0.0998,  0.0281, -0.0749,  0.0031, -0.0639, -0.0705, -0.0245,\n",
       "          0.0350,  0.0801,  0.0144, -0.0501, -0.0669,  0.0530, -0.0757, -0.0349,\n",
       "         -0.0868, -0.0636, -0.0696, -0.0794, -0.0877, -0.0937, -0.0134, -0.0880,\n",
       "         -0.0665,  0.0036,  0.0587, -0.0428,  0.0478, -0.0464,  0.0714, -0.0742,\n",
       "         -0.0079,  0.0334, -0.0572, -0.0785, -0.0503,  0.0019,  0.0682,  0.0437,\n",
       "          0.0142,  0.0646,  0.0054, -0.0490,  0.0272, -0.0606, -0.0857,  0.0544,\n",
       "         -0.0206,  0.0962, -0.0255, -0.0289,  0.0005,  0.0803, -0.0996, -0.0955,\n",
       "         -0.0339,  0.0851, -0.0271, -0.0050,  0.0052,  0.0216, -0.0925,  0.0524,\n",
       "          0.0185, -0.0049, -0.0222,  0.0564,  0.0997,  0.0542, -0.0973,  0.0974,\n",
       "         -0.0575, -0.0524, -0.0281,  0.0050,  0.0260, -0.0355, -0.0341,  0.0544,\n",
       "         -0.0670,  0.0169,  0.0595, -0.0768,  0.0890, -0.0686,  0.0939, -0.0235,\n",
       "         -0.0027,  0.0945, -0.0988,  0.0752],\n",
       "        [-0.0147,  0.0701,  0.0579, -0.0555, -0.0091,  0.0682,  0.0748, -0.0197,\n",
       "          0.0022, -0.0414, -0.0721, -0.0886,  0.0731,  0.0809, -0.0177,  0.0538,\n",
       "         -0.0238, -0.0658, -0.0357, -0.0164,  0.0491,  0.0750,  0.0454, -0.0978,\n",
       "         -0.0319, -0.0871, -0.0786, -0.0821,  0.0893, -0.0723, -0.0925, -0.0319,\n",
       "          0.0458, -0.0848, -0.0745, -0.0325,  0.0620,  0.0447, -0.0729,  0.0793,\n",
       "          0.0153,  0.0705, -0.0780, -0.0690, -0.0317, -0.0443, -0.0813, -0.0374,\n",
       "          0.0901,  0.0475, -0.0496,  0.0748, -0.0125, -0.0549,  0.0288, -0.0883,\n",
       "         -0.0889, -0.0004,  0.0466, -0.0979, -0.0132, -0.0377, -0.0175, -0.0801,\n",
       "         -0.0307, -0.0078,  0.0532, -0.0169,  0.0463,  0.0157, -0.0990, -0.0690,\n",
       "          0.0224,  0.0483, -0.0444, -0.0144,  0.0115, -0.0780, -0.0665,  0.0847,\n",
       "          0.0193, -0.0723, -0.0524, -0.0048, -0.0380, -0.0219, -0.0557, -0.0978,\n",
       "         -0.0381,  0.0462,  0.0531, -0.0169,  0.0444, -0.0146,  0.0699, -0.0354,\n",
       "         -0.0548,  0.0685, -0.0929, -0.0285],\n",
       "        [ 0.0523, -0.0846, -0.0238, -0.0073,  0.0165,  0.0265,  0.0362, -0.0209,\n",
       "          0.0234, -0.0586, -0.0539,  0.0214,  0.0061,  0.0885,  0.0045,  0.0851,\n",
       "         -0.0247, -0.0959,  0.0417, -0.0231,  0.0026, -0.0801, -0.0738, -0.0664,\n",
       "         -0.0957, -0.0278,  0.0451,  0.0198,  0.0802,  0.0857,  0.0112,  0.0727,\n",
       "         -0.0741,  0.0626, -0.0375,  0.0742,  0.0428, -0.0468, -0.0352, -0.0262,\n",
       "         -0.0585,  0.0178,  0.0846, -0.0615, -0.0676, -0.0657,  0.0496, -0.0443,\n",
       "         -0.0582, -0.0401, -0.0958,  0.0468, -0.0569, -0.0537,  0.0386,  0.0289,\n",
       "          0.0205, -0.0467, -0.0896,  0.0595,  0.0169, -0.0838,  0.0123,  0.0504,\n",
       "          0.0439,  0.0166,  0.0817,  0.0502, -0.0933, -0.0127,  0.0727, -0.0184,\n",
       "         -0.0851,  0.0530, -0.0275, -0.0050,  0.0354,  0.0602,  0.0417, -0.0106,\n",
       "          0.0241, -0.0582, -0.0742,  0.0338,  0.0965,  0.0814,  0.0531,  0.0301,\n",
       "          0.0567, -0.0103, -0.0640, -0.0491, -0.0799, -0.0845, -0.0347, -0.0286,\n",
       "          0.0484, -0.0176, -0.0216,  0.0921],\n",
       "        [ 0.0501,  0.0524,  0.0696,  0.0184,  0.0641, -0.0968,  0.0903, -0.0383,\n",
       "         -0.0102,  0.0769,  0.0146, -0.0413, -0.0285, -0.0727, -0.0833, -0.0595,\n",
       "         -0.0357,  0.0994, -0.0387, -0.0480,  0.0314,  0.0417, -0.0860,  0.0900,\n",
       "         -0.0340, -0.0476, -0.0481,  0.0836,  0.0604, -0.0235,  0.0379,  0.0835,\n",
       "         -0.0625, -0.0354, -0.0242, -0.0213,  0.0309,  0.0462,  0.0028, -0.0949,\n",
       "         -0.0178,  0.0732, -0.0496, -0.0776,  0.0132, -0.0916, -0.0781,  0.0914,\n",
       "         -0.0444, -0.0557, -0.0071, -0.0092, -0.0805, -0.0575,  0.0850,  0.0530,\n",
       "          0.0403, -0.0514,  0.0280,  0.0454,  0.0204, -0.0809,  0.0756, -0.0310,\n",
       "          0.0924, -0.0762, -0.0086,  0.0127, -0.0652,  0.0166,  0.0921,  0.0725,\n",
       "         -0.0711, -0.0092,  0.0182, -0.0188, -0.0163,  0.0538, -0.0308,  0.0667,\n",
       "          0.0031,  0.0491, -0.0973, -0.0300,  0.0470,  0.0312, -0.0467,  0.0067,\n",
       "          0.0072,  0.0193, -0.0516, -0.0993,  0.0502,  0.0223,  0.0753, -0.0405,\n",
       "          0.0420,  0.0758, -0.0884, -0.0124]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = net.to(device)\n",
    "\n",
    "net.linear.weight.data.uniform_(-0.1, 0.1)\n",
    "net.output.weight.data.uniform_(-0.1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQkjsvH7BRuB"
   },
   "source": [
    "**Loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q6WAiVnzulE7"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqN5BDW-BWb5"
   },
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrxsI3tth4sp"
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "    #turn off dropout\n",
    "    #net.eval()\n",
    "    \n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    correct_0 = 0\n",
    "    correct_1 = 0\n",
    "    correct_2 = 0\n",
    "    correct_3 = 0\n",
    "    correct_4 = 0\n",
    "    \n",
    "    h = torch.zeros(1, batch, 80)\n",
    "    c = torch.zeros(1, batch, 80)\n",
    "   \n",
    "    h=h.to(device)\n",
    "    c=c.to(device)\n",
    "       \n",
    "    for count in range(0,len(test_sample)-batch,batch) : #swap all test_sample with incomp_test_data if using created incomplete data \n",
    "               \n",
    "        minibatch_data =  unpack(test_sample[ count:count+batch ],max_stroke_len,max_point_len)\n",
    "        minibatch_label = test_label_tensor[ count:count+batch  ]\n",
    "        minibatch_label = torch.LongTensor([minibatch_label]).view(-1)\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        minibatch_data = minibatch_data.view(-1,3,max_point_len) \n",
    "        \n",
    "        scores = net( minibatch_data, h , c)\n",
    "        \n",
    "        loss = criterion(  scores ,  minibatch_label )    \n",
    "        \n",
    "        h=h.detach()\n",
    "        c=c.detach()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1        \n",
    "\n",
    "        #test accuracy\n",
    "        predicted = torch.argmax(scores,1)\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] == minibatch_label[i]:\n",
    "                correct+=1\n",
    "                if predicted[i] == 0:\n",
    "                    correct_0+=1\n",
    "                elif predicted[i] == 1:\n",
    "                    correct_1+=1\n",
    "                elif predicted[i] == 2:\n",
    "                    correct_2+=1                \n",
    "                elif predicted[i] == 3:\n",
    "                    correct_3+=1        \n",
    "                elif predicted[i] == 4:\n",
    "                    correct_4+=1                    \n",
    "    \n",
    "    total_loss = running_loss/num_batches \n",
    "    print('test: exp(loss) = ', math.exp(total_loss)  )\n",
    "    print ('correct', correct, correct_0, correct_1, correct_2, correct_3, correct_4)\n",
    "    print ('Test accuracy:{}%'.format(100 * correct / len(test_sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4923
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1092643,
     "status": "error",
     "timestamp": 1541692980263,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "ApWfPoXvulE_",
    "outputId": "06d2a7d8-076a-45e2-dc5d-2e53ff86de0d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch= 0 \t time= 480.8457133769989 \t exp(loss)= 3.0921130404376425\n",
      "Train accuracy:77.29270916609916%\n",
      "test: exp(loss) =  3.0750474819878164\n",
      "correct 98669 14447 22501 22573 20046 19102\n",
      "Test accuracy:77.90744498574801%\n",
      "\n",
      "epoch= 1 \t time= 1133.7705974578857 \t exp(loss)= 2.904844025393158\n",
      "Train accuracy:83.61176087407101%\n",
      "test: exp(loss) =  3.0084574099881225\n",
      "correct 101425 17182 21603 22739 19272 20629\n",
      "Test accuracy:80.08353796713752%\n",
      "\n",
      "epoch= 2 \t time= 1792.5708827972412 \t exp(loss)= 2.862937063149763\n",
      "Train accuracy:85.061439611524%\n",
      "test: exp(loss) =  3.0278751481873383\n",
      "correct 100528 15067 22856 23238 18333 21034\n",
      "Test accuracy:79.37528128923245%\n",
      "\n",
      "epoch= 3 \t time= 2452.4497134685516 \t exp(loss)= 2.8479812592381553\n",
      "Train accuracy:85.61335978444319%\n",
      "test: exp(loss) =  3.0041939859593394\n",
      "correct 101836 15583 23731 23114 18453 20955\n",
      "Test accuracy:80.40805691320105%\n",
      "\n",
      "epoch= 4 \t time= 3115.1949565410614 \t exp(loss)= 2.8352076321801674\n",
      "Train accuracy:86.06046249962988%\n",
      "test: exp(loss) =  3.0033759845518713\n",
      "correct 101375 16446 24002 22247 18439 20241\n",
      "Test accuracy:80.04405877661884%\n",
      "\n",
      "epoch= 5 \t time= 3775.441384077072 \t exp(loss)= 2.8092234309962936\n",
      "Train accuracy:86.99868731432406%\n",
      "test: exp(loss) =  2.9176516607846694\n",
      "correct 105332 17635 23477 23188 20430 20602\n",
      "Test accuracy:83.16844191426699%\n",
      "\n",
      "epoch= 6 \t time= 4440.251910448074 \t exp(loss)= 2.7913851980658673\n",
      "Train accuracy:87.64496293883674%\n",
      "test: exp(loss) =  2.9687779407075467\n",
      "correct 102555 15100 23700 22973 19909 20873\n",
      "Test accuracy:80.97576767285963%\n",
      "\n",
      "epoch= 7 \t time= 5105.480171442032 \t exp(loss)= 2.776839760880501\n",
      "Train accuracy:88.18740808732814%\n",
      "test: exp(loss) =  2.912203396481484\n",
      "correct 105559 17480 23898 23185 20559 20437\n",
      "Test accuracy:83.34767743922178%\n",
      "\n",
      "epoch= 8 \t time= 5764.240982532501 \t exp(loss)= 2.766282110507731\n",
      "Train accuracy:88.57805544863254%\n",
      "test: exp(loss) =  2.893475160831388\n",
      "correct 106432 18540 23507 22997 20315 21073\n",
      "Test accuracy:84.0369841056779%\n",
      "\n",
      "epoch= 9 \t time= 6423.472870588303 \t exp(loss)= 2.7510134499740033\n",
      "Train accuracy:89.12543550568007%\n",
      "test: exp(loss) =  2.889759456211592\n",
      "correct 106564 17684 23639 23179 20554 21508\n",
      "Test accuracy:84.14120916864721%\n",
      "\n",
      "epoch= 10 \t time= 7086.335465669632 \t exp(loss)= 2.74385888909957\n",
      "Train accuracy:89.39527630553006%\n",
      "test: exp(loss) =  2.868106223971346\n",
      "correct 107529 18167 23997 23314 20855 21196\n",
      "Test accuracy:84.90315754565768%\n",
      "\n",
      "epoch= 11 \t time= 7747.3001828193665 \t exp(loss)= 2.7374865079053405\n",
      "Train accuracy:89.61793937958329%\n",
      "test: exp(loss) =  2.8752944538442042\n",
      "correct 107232 17915 23822 23198 21431 20866\n",
      "Test accuracy:84.66865115397674%\n",
      "\n",
      "epoch= 12 \t time= 8407.66933298111 \t exp(loss)= 2.7272587948684195\n",
      "Train accuracy:90.01825916165774%\n",
      "test: exp(loss) =  2.8530413587502896\n",
      "correct 108197 18611 23330 23292 21544 21420\n",
      "Test accuracy:85.43059953098722%\n",
      "\n",
      "epoch= 13 \t time= 9070.583289146423 \t exp(loss)= 2.7172725475329673\n",
      "Train accuracy:90.39272002289798%\n",
      "test: exp(loss) =  2.8641946671383014\n",
      "correct 107664 18405 23475 23402 21049 21333\n",
      "Test accuracy:85.00975136005812%\n",
      "\n",
      "epoch= 14 \t time= 9734.477150678635 \t exp(loss)= 2.7146922682791024\n",
      "Train accuracy:90.46634885855565%\n",
      "test: exp(loss) =  2.847207541246086\n",
      "correct 108449 18565 23692 23277 21711 21204\n",
      "Test accuracy:85.62957465120135%\n",
      "\n",
      "epoch= 15 \t time= 10396.495606422424 \t exp(loss)= 2.70758445229098\n",
      "Train accuracy:90.75869284142165%\n",
      "test: exp(loss) =  2.844532569827984\n",
      "correct 108582 19383 23826 23099 20893 21381\n",
      "Test accuracy:85.73458929798103%\n",
      "\n",
      "epoch= 16 \t time= 11061.186394691467 \t exp(loss)= 2.703287033617838\n",
      "Train accuracy:90.91404376276908%\n",
      "test: exp(loss) =  2.855406046949994\n",
      "correct 108112 19009 23621 22747 20805 21930\n",
      "Test accuracy:85.36348490710546%\n",
      "\n",
      "epoch= 17 \t time= 11730.293359041214 \t exp(loss)= 2.6983055774249673\n",
      "Train accuracy:91.10453123303625%\n",
      "test: exp(loss) =  2.836515122220465\n",
      "correct 108979 19146 23686 23084 21524 21539\n",
      "Test accuracy:86.04805407069934%\n",
      "\n",
      "epoch= 18 \t time= 12392.642637252808 \t exp(loss)= 2.6938735140074814\n",
      "Train accuracy:91.27369989834088%\n",
      "test: exp(loss) =  2.839312370195943\n",
      "correct 108819 19121 23849 23070 20942 21837\n",
      "Test accuracy:85.92172066103957%\n",
      "\n",
      "epoch= 19 \t time= 13053.57540011406 \t exp(loss)= 2.6897407982271666\n",
      "Train accuracy:91.43299874653323%\n",
      "test: exp(loss) =  2.8350619776145005\n",
      "correct 109024 18974 23699 23363 21403 21585\n",
      "Test accuracy:86.08358534216615%\n",
      "\n",
      "epoch= 20 \t time= 13714.01795244217 \t exp(loss)= 2.687525992884457\n",
      "Train accuracy:91.51274686880052%\n",
      "test: exp(loss) =  2.8299326976708508\n",
      "correct 109246 19266 23716 23222 21497 21545\n",
      "Test accuracy:86.25887294806907%\n",
      "\n",
      "epoch= 21 \t time= 14376.822832107544 \t exp(loss)= 2.6841395638419137\n",
      "Train accuracy:91.63710656441536%\n",
      "test: exp(loss) =  2.829552693094003\n",
      "correct 109265 19210 23785 23124 21429 21717\n",
      "Test accuracy:86.27387504046617%\n",
      "\n",
      "epoch= 22 \t time= 15039.753775835037 \t exp(loss)= 2.6815989314773145\n",
      "Train accuracy:91.75337300999813%\n",
      "test: exp(loss) =  2.828637969534496\n",
      "correct 109294 19277 23787 23219 21768 21243\n",
      "Test accuracy:86.296772970967%\n",
      "\n",
      "epoch= 23 \t time= 15700.08400630951 \t exp(loss)= 2.678848092506961\n",
      "Train accuracy:91.85542691893919%\n",
      "test: exp(loss) =  2.826655682732609\n",
      "correct 109382 19247 23837 23134 21421 21743\n",
      "Test accuracy:86.36625634627988%\n",
      "\n",
      "epoch= 24 \t time= 16358.252659082413 \t exp(loss)= 2.6771006424924124\n",
      "Train accuracy:91.94149172415835%\n",
      "test: exp(loss) =  2.8304397411845117\n",
      "correct 109204 19097 23816 23113 21498 21680\n",
      "Test accuracy:86.22571042803338%\n",
      "\n",
      "epoch= 25 \t time= 17018.220947742462 \t exp(loss)= 2.6746273192297187\n",
      "Train accuracy:92.02380599887483%\n",
      "test: exp(loss) =  2.827461021227373\n",
      "correct 109338 19198 23716 23209 21445 21770\n",
      "Test accuracy:86.33151465862343%\n",
      "\n",
      "epoch= 26 \t time= 17676.473779678345 \t exp(loss)= 2.672928123253857\n",
      "Train accuracy:92.08993377352718%\n",
      "test: exp(loss) =  2.8314069465148863\n",
      "correct 109137 19247 23831 23212 21383 21464\n",
      "Test accuracy:86.17280831273835%\n",
      "\n",
      "epoch= 27 \t time= 18336.36983704567 \t exp(loss)= 2.672409586168195\n",
      "Train accuracy:92.1150031089924%\n",
      "test: exp(loss) =  2.825960702191448\n",
      "correct 109413 19402 23880 23048 21258 21825\n",
      "Test accuracy:86.39073344440146%\n",
      "\n",
      "epoch= 28 \t time= 18996.74668622017 \t exp(loss)= 2.6702766278495056\n",
      "Train accuracy:92.20501584105646%\n",
      "test: exp(loss) =  2.8276908183194296\n",
      "correct 109332 19232 23863 23153 21594 21490\n",
      "Test accuracy:86.32677715576119%\n",
      "\n",
      "epoch= 29 \t time= 19655.682705402374 \t exp(loss)= 2.6688086303622933\n",
      "Train accuracy:92.2594972315163%\n",
      "test: exp(loss) =  2.8255362389281835\n",
      "correct 109446 19150 23946 23108 21551 21691\n",
      "Test accuracy:86.41678971014379%\n",
      "\n",
      "epoch= 30 \t time= 20316.71349811554 \t exp(loss)= 2.667656275000219\n",
      "Train accuracy:92.31851873784778%\n",
      "test: exp(loss) =  2.8265465789836774\n",
      "correct 109389 19179 23829 23199 21700 21482\n",
      "Test accuracy:86.3717834329525%\n",
      "\n",
      "epoch= 31 \t time= 20976.445166110992 \t exp(loss)= 2.666443778434392\n",
      "Train accuracy:92.36451208559106%\n",
      "test: exp(loss) =  2.8240494599919432\n",
      "correct 109523 19234 23758 23264 21739 21528\n",
      "Test accuracy:86.47758766354255%\n",
      "\n",
      "epoch= 32 \t time= 21636.78901386261 \t exp(loss)= 2.665678030763366\n",
      "Train accuracy:92.38267254907767%\n",
      "test: exp(loss) =  2.824795121602653\n",
      "correct 109445 19194 23913 23091 21651 21596\n",
      "Test accuracy:86.41600012633342%\n",
      "\n",
      "epoch= 33 \t time= 22295.771285772324 \t exp(loss)= 2.6643371841715076\n",
      "Train accuracy:92.43774612856424%\n",
      "test: exp(loss) =  2.823227464509529\n",
      "correct 109536 19169 23874 23272 21735 21486\n",
      "Test accuracy:86.4878522530774%\n",
      "\n",
      "epoch= 34 \t time= 22957.439281463623 \t exp(loss)= 2.663370382417197\n",
      "Train accuracy:92.48551604338772%\n",
      "test: exp(loss) =  2.821723892714071\n",
      "correct 109639 19294 23826 23202 21677 21640\n",
      "Test accuracy:86.56917938554588%\n",
      "\n",
      "epoch= 35 \t time= 23617.948029518127 \t exp(loss)= 2.6616506024958917\n",
      "Train accuracy:92.54216879361225%\n",
      "test: exp(loss) =  2.823466578714004\n",
      "correct 109532 19175 23858 23212 21726 21561\n",
      "Test accuracy:86.48469391783591%\n",
      "\n",
      "epoch= 36 \t time= 24277.759769439697 \t exp(loss)= 2.6604865675756564\n",
      "Train accuracy:92.6100731353448%\n",
      "test: exp(loss) =  2.8222234701537623\n",
      "correct 109575 19360 23838 23124 21635 21618\n",
      "Test accuracy:86.51864602168197%\n",
      "\n",
      "epoch= 37 \t time= 24940.661194086075 \t exp(loss)= 2.6596450852017894\n",
      "Train accuracy:92.63494507446777%\n",
      "test: exp(loss) =  2.8220037997488387\n",
      "correct 109590 19271 23883 23213 21649 21574\n",
      "Test accuracy:86.53048977883758%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch= 38 \t time= 25601.375392198563 \t exp(loss)= 2.6580496186883473\n",
      "Train accuracy:92.69396658079926%\n",
      "test: exp(loss) =  2.8218789200846746\n",
      "correct 109598 19237 23801 23254 21627 21679\n",
      "Test accuracy:86.53680644932057%\n",
      "\n",
      "epoch= 39 \t time= 26260.699600458145 \t exp(loss)= 2.656187017929018\n",
      "Train accuracy:92.77766262991146%\n",
      "test: exp(loss) =  2.8226478205580006\n",
      "correct 109555 19298 23891 23146 21728 21492\n",
      "Test accuracy:86.5028543454745%\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "lr = 0.004\n",
    "\n",
    "for epoch in range(40):\n",
    "    #enable dropout\n",
    "    #net.train()\n",
    "    \n",
    "    train_correct = 0\n",
    "    \n",
    "    if epoch > 2:\n",
    "        lr = lr / 1.15\n",
    "    \n",
    "    if lr < 0.0002:\n",
    "        lr = 0.0002\n",
    "      \n",
    "    optimizer=torch.optim.Adam( net.parameters(),lr = lr)\n",
    "        \n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    h = torch.zeros( 1, batch, 80)\n",
    "    c = torch.zeros( 1, batch, 80)\n",
    "    \n",
    "    h=h.to(device)\n",
    "    c=c.to(device)\n",
    "    \n",
    "    for count in range(0,len(train_sample)-batch, batch):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        minibatch_data = unpack(train_sample[ count:count+batch],max_stroke_len,max_point_len)\n",
    "        minibatch_label = train_label_tensor[count:count+batch]\n",
    "        minibatch_label = torch.LongTensor([minibatch_label]).view(-1)\n",
    "\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        h=h.detach()\n",
    "        c=c.detach()\n",
    "        h=h.requires_grad_()\n",
    "        c=c.requires_grad_()\n",
    "               \n",
    "        minibatch_data = minibatch_data.view(-1,3,max_point_len) \n",
    "              \n",
    "        scores = net( minibatch_data, h , c )        \n",
    "        loss = criterion(  scores ,  minibatch_label )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                     \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # training accuracy\n",
    "        predicted = torch.argmax(scores,1)\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] == minibatch_label[i]:\n",
    "                train_correct+=1\n",
    "            \n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    print('')\n",
    "    print('epoch=',epoch, '\\t time=', elapsed, '\\t exp(loss)=',  math.exp(total_loss))\n",
    "    print ('Train accuracy:{}%'.format(100 * train_correct / len(train_sample)))\n",
    "    eval_on_test_set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1005,
     "status": "ok",
     "timestamp": 1541568175904,
     "user": {
      "displayName": "邱阳",
      "photoUrl": "https://lh6.googleusercontent.com/-bVcoO7oOihM/AAAAAAAAAAI/AAAAAAAAAD8/AeiDOukU-8k/s64/photo.jpg",
      "userId": "08264021515608885541"
     },
     "user_tz": -480
    },
    "id": "NaD7sZpyYpwr",
    "outputId": "ee4b78b0-4039-4c7e-d08a-d749963e0f3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type lstm_cnn. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#checkpoint\n",
    "outpath = ''\n",
    "torch.save(net, 'CRCNN_92.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkOAphIsn5iC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RD3rLfs9I33W"
   ],
   "name": "cnn_lstm_cnn_batch.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

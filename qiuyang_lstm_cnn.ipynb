{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "zkaNR3VhBoPw",
        "o02U9T9NDWcE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8GrIEHEhAKcZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Author: Qiu Yang\n",
        "\n",
        "LSTM encoder, CNN decoder\n",
        "\n",
        "Data used is toy_dataset in Github, 87% on full test image, 28.7% on half image(shown below) \n",
        "\n",
        "Skip the create incomplete dataset section if testing with complete image. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MtsFQfHzulET",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import os.path as path\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.path import Path\n",
        "#import generate_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZmsvnbXRulEZ",
        "outputId": "232df268-22ac-4356-dbb4-ce19c257e426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "device= torch.device(\"cuda\")\n",
        "#device= torch.device(\"cpu\")\n",
        "print(device)\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "suS_js-gABnF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ]
    },
    {
      "metadata": {
        "id": "ZqIfo7oPm20Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**unpack dataset**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jtkWxu9lulEh",
        "outputId": "4ab9174e-0126-4723-9b44-8ff6f0d0b0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "data_path  = ''\n",
        "with open(path.join(data_path,'data_X'),'rb') as f:\n",
        "    X=pickle.load(f)\n",
        "    \n",
        "with open(path.join(data_path,'data_Y'),'rb') as f:\n",
        "    Y=pickle.load(f)\n",
        "    \n",
        "len_train_X=int(len(X)*0.8) #partition data into training and testing\n",
        "\n",
        "train_data_raw=np.array(X[:len_train_X])\n",
        "train_label=np.array(Y[:len_train_X])\n",
        "test_data_raw=np.array(X[len_train_X:])\n",
        "test_label=np.array(Y[len_train_X:])\n",
        "\n",
        "\n",
        "print(len(train_data_raw),len(train_label))\n",
        "\n",
        "print(len(test_data_raw),len(test_label))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35685 35685\n",
            "8922 8922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F5Y9weAxLdIf",
        "colab_type": "code",
        "outputId": "bf9acf40-1f12-4953-9d1a-1c2c51e5a95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#check classes\n",
        "a = set(train_label)\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'penguin', 'snowman', 'calendar', 'teddy-bear', 'blackberry'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQq4PTdismBO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**A random sample**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1QvGLEOiulEn",
        "outputId": "853ce008-1e85-4201-b8c6-104f4f04d4ee",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "sketch = random.choice(train_data_raw)\n",
        "for i in range(len(sketch)):\n",
        "    plt.plot(sketch[i][0][:], sketch[i][1][:])\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAFKCAYAAAA5RqfXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEUhTQghhCQoCmlCCCEkQf0PZ/NKsh7GrGIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5d87ca3cc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FJEk8gg3ASTG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sub-sampling(for faster run) and reformat**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AsYZrNVwulEt",
        "outputId": "19c0bf01-9a6a-4802-d99e-a835ccd8cde2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "#sub sample\n",
        "train_size=5000\n",
        "test_size=1000\n",
        "train_sample = train_data_raw[0:train_size]\n",
        "train_label_sample = train_label[0:train_size]\n",
        "test_sample = test_data_raw[0:test_size]\n",
        "test_label_sample = test_label[0:test_size]\n",
        "print(len(train_sample))\n",
        "\n",
        "#reformat into [x,y,l]\n",
        "no_point = 0; \n",
        "\n",
        "def get_min_max_len(sub_sample):\n",
        "    max_stroke_length = 0\n",
        "    max_point_length = 0\n",
        "    min_storkes_length = 500;\n",
        "    for i in range(len(sub_sample)):\n",
        "        if len(sub_sample[i])> max_stroke_length: \n",
        "            max_stroke_length = len(sub_sample[i])\n",
        "        if len(sub_sample[i]) < min_storkes_length:\n",
        "            min_storkes_length = len(sub_sample[i])\n",
        "        for j in range(len(sub_sample[i])): \n",
        "            if len(sub_sample[i][j][0])> max_point_length:\n",
        "                max_point_length = len(sub_sample[i][j][0])\n",
        "    return max_stroke_length,max_point_length,min_storkes_length\n",
        "                \n",
        "max_stroke_len,max_point_len,min_stroke_len = get_min_max_len(train_sample)    \n",
        "print (max_stroke_len,max_point_len,min_stroke_len)\n",
        "\n",
        "def process_data(sub_sample, append):\n",
        "    stroke_data = []\n",
        "    point_data = []\n",
        "    for i in range(len(sub_sample)): #image\n",
        "        for j in range(len(sub_sample[i])): #strokes\n",
        "            for k in range(len(sub_sample[i][j][0])): #points\n",
        "                if append:\n",
        "                    if k == len(sub_sample[i][j][0])-1:\n",
        "                        temp2 = [sub_sample[i][j][0][k],sub_sample[i][j][1][k],1]\n",
        "                    else:\n",
        "                        temp2 = [sub_sample[i][j][0][k],sub_sample[i][j][1][k],0]\n",
        "                    point_data.append(temp2)\n",
        "                else:\n",
        "                    temp = [sub_sample[i][j][0][k],sub_sample[i][j][1][k]]\n",
        "                    point_data.append(temp)\n",
        "        stroke_data.append(point_data)\n",
        "        point_data = []\n",
        "            \n",
        "    return stroke_data   \n",
        "\n",
        "train_data = process_data(train_sample, 1)\n",
        "test_data = process_data(test_sample, 1)\n",
        "\n",
        "print (len(train_data))\n",
        "print (len(test_data))\n",
        "print(train_data_raw[0])\n",
        "print(train_data[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "61 349 1\n",
            "5000\n",
            "1000\n",
            "[[[30, 24, 23, 25, 33, 68, 131, 151, 160, 163, 164, 150, 128, 79, 49, 37], [90, 81, 41, 34, 26, 12, 0, 17, 32, 48, 99, 114, 118, 117, 103, 85]], [[58, 43, 21, 10, 1, 0, 14, 27, 158, 166, 193, 193, 189, 183, 173, 133, 62, 56, 50], [243, 241, 234, 225, 210, 168, 145, 140, 132, 135, 180, 220, 233, 240, 247, 255, 251, 250, 241]]]\n",
            "[[30, 90, 0], [24, 81, 0], [23, 41, 0], [25, 34, 0], [33, 26, 0], [68, 12, 0], [131, 0, 0], [151, 17, 0], [160, 32, 0], [163, 48, 0], [164, 99, 0], [150, 114, 0], [128, 118, 0], [79, 117, 0], [49, 103, 0], [37, 85, 1], [58, 243, 0], [43, 241, 0], [21, 234, 0], [10, 225, 0], [1, 210, 0], [0, 168, 0], [14, 145, 0], [27, 140, 0], [158, 132, 0], [166, 135, 0], [193, 180, 0], [193, 220, 0], [189, 233, 0], [183, 240, 0], [173, 247, 0], [133, 255, 0], [62, 251, 0], [56, 250, 0], [50, 241, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6t9V5ZoNWOZd",
        "outputId": "164fbd52-6773-4658-f068-e8b6efbe150b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#string to int label for classes\n",
        "label_set = set(train_label_sample)\n",
        "label_list = list(label_set)\n",
        "train_label_tensor = []\n",
        "for i in range(len(train_label_sample)):\n",
        "    train_label_tensor.append(label_list.index(train_label_sample[i]))\n",
        "test_label_set = set(test_label)\n",
        "test_label_list = list(test_label_set)\n",
        "test_label_tensor = []\n",
        "for i in range(len(test_label_sample)):\n",
        "    test_label_tensor.append(test_label_list.index(test_label_sample[i]))  \n",
        "print (len(train_label_tensor),train_label_tensor[0],len(test_label_tensor))\n",
        "print(set(train_label_tensor),set(test_label_tensor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 1 1000\n",
            "{0, 1, 2, 3, 4} {0, 1, 2, 3, 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hJ3l-ybxfMn4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Create incomplete test image (Skip if using complete test data)**"
      ]
    },
    {
      "metadata": {
        "id": "QACHhwSWfMLm",
        "colab_type": "code",
        "outputId": "07ae6031-561d-4978-b60f-1ea12cccbb0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "dup_sample = test_sample.copy()\n",
        "dup_label = test_label_tensor.copy()\n",
        "print(len(dup_sample))\n",
        "\n",
        "min_num_strokes = 2\n",
        "percentage = 0.5   #percentage of the stokes\n",
        "\n",
        "def sample_random_strokes(dataset,labelset,rand,percent): #rand=1: take stroke randomly, rand=0: take sequentially\n",
        "    new_set = []\n",
        "    new_strokes = []\n",
        "    for i in range(len(dataset)):\n",
        "        if len(dataset[i]) < min_num_strokes:\n",
        "            labelset.remove(labelset[i])\n",
        "            continue\n",
        "        if rand:\n",
        "            for j in range(int(len(dataset[i])*percent)):                \n",
        "                stroke = dataset[i].pop(random.randrange(len(dataset[i])))\n",
        "                new_strokes.append(stroke)\n",
        "        else:\n",
        "            for j in range(int(len(dataset[i])*percent)):                \n",
        "                stroke = dataset[i][j]\n",
        "                new_strokes.append(stroke) \n",
        "                \n",
        "        new_set.append(new_strokes)  \n",
        "        new_strokes = []\n",
        "        \n",
        "    return new_set\n",
        "\n",
        "a= sample_random_strokes(dup_sample,dup_label, 1 ,percentage)\n",
        "print(len(a),len(dup_label))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n",
            "989 989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dh2sy_Va7ox_",
        "colab_type": "code",
        "outputId": "1dd8b95f-f238-44e6-9c11-20cc29a0b9a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "incomp_test_data = process_data(a, 1)\n",
        "print(len(incomp_test_data),incomp_test_data[0],len(dup_label))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "989 [[137, 46, 0], [141, 49, 1], [77, 99, 0], [62, 102, 0], [23, 135, 0], [7, 158, 0], [0, 178, 0], [20, 187, 0], [32, 178, 0], [50, 154, 0], [47, 206, 0], [59, 231, 0], [126, 254, 0], [169, 253, 0], [175, 246, 0], [127, 223, 0], [201, 224, 0], [216, 217, 0], [225, 203, 0], [225, 196, 0], [220, 192, 0], [198, 184, 0], [174, 183, 1], [134, 29, 0], [121, 24, 0], [123, 15, 0], [130, 10, 0], [138, 10, 0], [139, 17, 0], [126, 30, 1], [112, 81, 0], [167, 79, 0], [154, 95, 0], [142, 100, 0], [120, 99, 0], [112, 93, 0], [106, 83, 1]] 989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t5AZJyDtA7UZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-on5907pulEw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#parameters\n",
        "#train\n",
        "bs = 50\n",
        "lr = 12\n",
        "Epoch = 12\n",
        "#lstm\n",
        "input_size = 3\n",
        "hidden_size = 300\n",
        "feature_size = 64\n",
        "#cnn\n",
        "channels = 1 \n",
        "kernels = 50\n",
        "kernel_size = 5\n",
        "pool_size = 2\n",
        "output_size = 5\n",
        "temp_size = 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hP03VKgjX7d5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Model_1: one score for each point**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4nOUBWUOulEz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class lstm_cnn (nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(lstm_cnn, self).__init__()        \n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.conv = nn.Conv2d(channels, kernels, kernel_size = kernel_size, padding = 1)\n",
        "        self.pool = nn.MaxPool2d(pool_size, pool_size)\n",
        "        self.linear2 = nn.Linear(2700, 100)\n",
        "        self.output = nn.Linear(100, output_size) \n",
        "       \n",
        "    def forward(self, point_seq, h_init, c_init ):\n",
        "        score_seq = torch.LongTensor([0])\n",
        "        h_seq , (h_final,c_final)  =   self.lstm( point_seq , (h_init,c_init) )\n",
        "        h_seq_shaped = h_seq.view(1,1,-1,hidden_size)\n",
        "        for i in range(h_seq_shaped.shape[2]):\n",
        "            temp = h_seq_shaped[:,:,i,:]\n",
        "            temp = temp.reshape(1,1,20,15)\n",
        "            temp = self.conv(temp)\n",
        "            temp = F.relu(temp)\n",
        "            temp = self.pool(temp)\n",
        "            temp_size = torch.numel(temp)\n",
        "            temp = temp.reshape(-1,temp_size)\n",
        "            temp = self.linear2(temp)\n",
        "            temp = F.relu(temp)\n",
        "            score = self.output(temp)            \n",
        "            if i== 0:\n",
        "                score_seq = score                \n",
        "            else:\n",
        "                score_seq = torch.cat((score_seq, score),0)\n",
        "\n",
        "        return score_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3rxaHZ9fhNZw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build the net**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Jio9zcAJulE1",
        "outputId": "5aa7965c-2fcf-4ad0-b55f-26df49e70242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "def display_num_param(net):\n",
        "    nb_param = 0\n",
        "    for param in net.parameters():\n",
        "        nb_param += param.numel()\n",
        "    print('There are {} ({:.2f} million) parameters in this neural network'.format(\n",
        "        nb_param, nb_param/1e6)\n",
        "         )\n",
        "\n",
        "net = lstm_cnn()\n",
        "\n",
        "print(net)\n",
        "\n",
        "display_num_param(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm_cnn(\n",
            "  (lstm): LSTM(3, 300, batch_first=True)\n",
            "  (conv): Conv2d(1, 50, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear2): Linear(in_features=2700, out_features=100, bias=True)\n",
            "  (output): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "There are 637905 (0.64 million) parameters in this neural network\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lt68k2gSulE5",
        "outputId": "cc0cf229-7b14-4c9f-fcbf-e4618c6a176f",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "net = net.to(device)\n",
        "\n",
        "net.linear2.weight.data.uniform_(-0.1, 0.1)\n",
        "net.output.weight.data.uniform_(-0.1, 0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0100,  0.0597,  0.0020,  0.0450,  0.0966, -0.0704, -0.0304,  0.0188,\n",
              "         -0.0408,  0.0020,  0.0853, -0.0938, -0.0546, -0.0725, -0.0177,  0.0601,\n",
              "          0.0694,  0.0202, -0.0189,  0.0798, -0.0658,  0.0693, -0.0447, -0.0021,\n",
              "         -0.0933, -0.0192, -0.0239, -0.0793,  0.0595, -0.0302, -0.0527, -0.0841,\n",
              "         -0.0377, -0.0586, -0.0734,  0.0559, -0.0231, -0.0110,  0.0060, -0.0174,\n",
              "          0.0304, -0.0592, -0.0080,  0.0910, -0.0076, -0.0616, -0.0881, -0.0463,\n",
              "          0.0204,  0.0507, -0.0249,  0.0115,  0.0592, -0.0587,  0.0267, -0.0435,\n",
              "         -0.0712, -0.0974,  0.0385, -0.0267, -0.0930,  0.0508, -0.0589,  0.0943,\n",
              "         -0.0031,  0.0970,  0.0959, -0.0476, -0.0041,  0.0701, -0.0765,  0.0604,\n",
              "         -0.0398,  0.0652, -0.0013, -0.0108,  0.0170,  0.0224, -0.0604, -0.0905,\n",
              "         -0.0098, -0.0564,  0.0527, -0.0160,  0.0618, -0.0184, -0.0510, -0.0305,\n",
              "          0.0171, -0.0185,  0.0387,  0.0217,  0.0552, -0.0716, -0.0035, -0.0096,\n",
              "         -0.0229, -0.0513, -0.0737,  0.0428],\n",
              "        [-0.0477, -0.0358,  0.0378,  0.0763, -0.0832,  0.0377, -0.0293,  0.0791,\n",
              "          0.0107, -0.0106,  0.0447,  0.0677,  0.0403,  0.0364, -0.0317,  0.0211,\n",
              "          0.0612,  0.0149,  0.0137, -0.0879, -0.0135,  0.0717, -0.0439, -0.0897,\n",
              "         -0.0713, -0.0130,  0.0447, -0.0265, -0.0789, -0.0834, -0.0577, -0.0268,\n",
              "         -0.0796,  0.0969, -0.0329,  0.0566, -0.0274, -0.0244,  0.0809, -0.0967,\n",
              "         -0.0724,  0.0386,  0.0549,  0.0532, -0.0812, -0.0083,  0.0570,  0.0760,\n",
              "          0.0442,  0.0802, -0.0395, -0.0993, -0.0887, -0.0199,  0.0777, -0.0719,\n",
              "         -0.0006,  0.0594, -0.0714,  0.0404, -0.0515,  0.0504,  0.0652,  0.0487,\n",
              "         -0.0472, -0.0959,  0.0165, -0.0577,  0.0206,  0.0703,  0.0920, -0.0787,\n",
              "         -0.0991,  0.0198, -0.0616, -0.0930, -0.0539,  0.0447, -0.0043, -0.0910,\n",
              "         -0.0499, -0.0875, -0.0069, -0.0700, -0.0662,  0.0891, -0.0827, -0.0258,\n",
              "         -0.0040,  0.0522,  0.0319,  0.0842,  0.0524,  0.0637, -0.0908, -0.0511,\n",
              "         -0.0237, -0.0612,  0.0362, -0.0956],\n",
              "        [-0.0843, -0.0524, -0.0614, -0.0908,  0.0903, -0.0178,  0.0149, -0.0285,\n",
              "         -0.0505, -0.0883,  0.0555,  0.0089, -0.0721,  0.0759, -0.0949,  0.0078,\n",
              "          0.0136, -0.0651,  0.0279, -0.0477, -0.0350, -0.0094, -0.0585, -0.0702,\n",
              "          0.0634, -0.0096,  0.0471, -0.0639,  0.0039, -0.0923,  0.0795, -0.0265,\n",
              "          0.0750, -0.0999,  0.0511,  0.0417, -0.0986,  0.0485, -0.0046,  0.0153,\n",
              "         -0.0230,  0.0511, -0.0487,  0.0246,  0.0326,  0.0216,  0.0680, -0.0680,\n",
              "         -0.0645,  0.0628, -0.0328,  0.0260, -0.0052,  0.0506,  0.0948,  0.0732,\n",
              "         -0.0893, -0.0818,  0.0310, -0.0311,  0.0409,  0.0461,  0.0371, -0.0637,\n",
              "         -0.0696,  0.0854, -0.0219, -0.0779,  0.0627, -0.0501,  0.0094,  0.0296,\n",
              "         -0.0204,  0.0336, -0.0049, -0.0944,  0.0644,  0.0918,  0.0357, -0.0182,\n",
              "         -0.0978, -0.0452, -0.0976, -0.0468, -0.0463, -0.0942,  0.0489,  0.0241,\n",
              "         -0.0864, -0.0862,  0.0558, -0.0663, -0.0002, -0.0626, -0.0881,  0.0624,\n",
              "         -0.0737, -0.0052,  0.0186, -0.0907],\n",
              "        [-0.0500, -0.0110, -0.0337,  0.0456,  0.0401, -0.0662,  0.0377,  0.0406,\n",
              "         -0.0026,  0.0812,  0.0707,  0.0267, -0.0710,  0.0399,  0.0686, -0.0051,\n",
              "         -0.0179, -0.0815,  0.0754,  0.0004, -0.0528,  0.0904,  0.0453,  0.0225,\n",
              "         -0.0995, -0.0643, -0.0138,  0.0686,  0.0949,  0.0713, -0.0766, -0.0072,\n",
              "          0.0254, -0.0597, -0.0740,  0.0977,  0.0843, -0.0351, -0.0148, -0.0054,\n",
              "          0.0130,  0.0449,  0.0698,  0.0654,  0.0519,  0.0416,  0.0826,  0.0844,\n",
              "         -0.0384, -0.0160, -0.0500, -0.0843, -0.0720, -0.0547,  0.0180, -0.0344,\n",
              "         -0.0867,  0.0956,  0.0026,  0.0148,  0.0317,  0.0312, -0.0709, -0.0530,\n",
              "          0.0612, -0.0882, -0.0063,  0.0848,  0.0824, -0.0879,  0.0323, -0.0569,\n",
              "          0.0594,  0.0257,  0.0797,  0.0031, -0.0729, -0.0152,  0.0595, -0.0140,\n",
              "          0.0964, -0.0348, -0.0521,  0.0003,  0.0670, -0.0390,  0.0553,  0.0600,\n",
              "         -0.0183, -0.0851, -0.0044,  0.0679,  0.0920,  0.0879, -0.0779,  0.0175,\n",
              "         -0.0044,  0.0278,  0.0656,  0.0392],\n",
              "        [-0.0157,  0.0212, -0.0260, -0.0486, -0.0190, -0.0327,  0.0507,  0.0572,\n",
              "         -0.0900, -0.0283, -0.0810,  0.0884, -0.0739, -0.0610, -0.0305,  0.0301,\n",
              "          0.0457, -0.0492,  0.0168, -0.0337, -0.0709, -0.0440, -0.0551,  0.0153,\n",
              "          0.0697,  0.0109, -0.0214, -0.0328,  0.0197,  0.0606, -0.0598,  0.0437,\n",
              "         -0.0110,  0.0417,  0.0908,  0.0645, -0.0562,  0.0924,  0.0876, -0.0573,\n",
              "          0.0596, -0.0976, -0.0885, -0.0974, -0.0295,  0.0463,  0.0082,  0.0315,\n",
              "          0.0547, -0.0888, -0.0559, -0.0843,  0.0463, -0.0275,  0.0591,  0.0535,\n",
              "          0.0327,  0.0359,  0.0133, -0.0393,  0.0328,  0.0836, -0.0710, -0.0780,\n",
              "          0.0894,  0.0888, -0.0059, -0.0894, -0.0522,  0.0556,  0.0821, -0.0158,\n",
              "         -0.0941,  0.0769,  0.0752, -0.0664,  0.0112,  0.0946, -0.0075,  0.0183,\n",
              "          0.0971, -0.0800, -0.0036, -0.0709,  0.0652,  0.0980, -0.0087,  0.0817,\n",
              "         -0.0793,  0.0704,  0.0678, -0.0527, -0.0766, -0.0656,  0.0882,  0.0766,\n",
              "          0.0150,  0.0518,  0.0808,  0.0774]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "zQkjsvH7BRuB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loss function**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q6WAiVnzulE7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TqN5BDW-BWb5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training and evaluation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-ytfpXc5ulE9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_on_test_set():\n",
        "\n",
        "    running_loss=0\n",
        "    num_batches=0    \n",
        "    \n",
        "    correct = 0\n",
        "    \n",
        "    correct_0 = 0\n",
        "    correct_1 = 0\n",
        "    correct_2 = 0\n",
        "    correct_3 = 0\n",
        "    correct_4 = 0\n",
        "    \n",
        "    h = torch.zeros(1, 1, hidden_size)\n",
        "    c = torch.zeros(1, 1, hidden_size)\n",
        "   \n",
        "    h=h.to(device)\n",
        "    c=c.to(device)\n",
        "       \n",
        "    for count in range( len(incomp_test_data)) : #change all incomp_test_data to test_data if testing complete image\n",
        "               \n",
        "        minibatch_data =  incomp_test_data[ count  ]\n",
        "        minibatch_data = torch.Tensor(minibatch_data).view(1,-1,3)\n",
        "\n",
        "        minibatch_label = []\n",
        "        for i in range(minibatch_data.shape[1]):\n",
        "            minibatch_label.append(dup_label[ count ])\n",
        "        minibatch_label = torch.LongTensor([minibatch_label]).view(-1)\n",
        "        \n",
        "        minibatch_data=minibatch_data.to(device)\n",
        "        minibatch_label=minibatch_label.to(device)\n",
        "                                  \n",
        "        scores = net( minibatch_data, h , c)\n",
        "\n",
        "        loss = criterion(  scores ,  minibatch_label )    \n",
        "        \n",
        "        h=h.detach()\n",
        "        c=c.detach()\n",
        "            \n",
        "        running_loss += loss.item()\n",
        "        num_batches += 1        \n",
        "        \n",
        "        scores = F.relu(scores)\n",
        "        total_score = torch.sum(scores,0)  \n",
        "        _, predicted = torch.max(total_score,0)\n",
        "\n",
        "        if predicted == minibatch_label[0]:\n",
        "            correct+=1\n",
        "            if predicted == 0:\n",
        "                correct_0+=1\n",
        "            elif predicted == 1:\n",
        "                correct_1+=1\n",
        "            elif predicted == 2:\n",
        "                correct_2+=1                \n",
        "            elif predicted == 3:\n",
        "                correct_3+=1   \n",
        "            elif predicted == 4:\n",
        "                correct_4+=1                \n",
        "    \n",
        "    total_loss = running_loss/num_batches \n",
        "    print('test: exp(loss) = ', math.exp(total_loss)  )\n",
        "    print ('correct', correct, 'c_0', correct_0,'c_1',correct_1,'c_2', correct_2,'c_3',correct_3,'c_4',correct_4)\n",
        "    print ('Test accuracy:{}%'.format(100 * correct / len(test_data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e3zJC8lnLDwi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training by batch of image (not exactly by batch, append in 1 row to avoid uneven tensor shape. )**"
      ]
    },
    {
      "metadata": {
        "id": "l5kaU45LK_pk",
        "colab_type": "code",
        "outputId": "fd03e133-5d61-48bc-d3d3-06f37b8bef34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        }
      },
      "cell_type": "code",
      "source": [
        "start=time.time()\n",
        "\n",
        "for epoch in range(Epoch):\n",
        "    \n",
        "    optimizer=torch.optim.Adam( net.parameters())\n",
        "        \n",
        "    running_loss=0\n",
        "    num_batches=0    \n",
        "       \n",
        "    h = torch.zeros( 1, 1, hidden_size)\n",
        "    c = torch.zeros( 1, 1, hidden_size)\n",
        "   \n",
        "    h=h.to(device)\n",
        "    c=c.to(device)\n",
        "    \n",
        "    for count in range(0,len(train_data),bs):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        minibatch_data_bs =  train_data[ count:count+bs]\n",
        "        \n",
        "        minibatch_data = []\n",
        "        for i in range(len(minibatch_data_bs)):\n",
        "            for j in range (len(minibatch_data_bs[i])):\n",
        "                minibatch_data.append(minibatch_data_bs[i][j])          \n",
        "        minibatch_data = torch.Tensor(minibatch_data).view(1,-1,3)\n",
        "\n",
        "        minibatch_label = []\n",
        "        for k in range(len(minibatch_data_bs)):\n",
        "            for l in range(len(minibatch_data_bs[k])):\n",
        "                minibatch_label.append(train_label_tensor[ count+k ])       \n",
        "        minibatch_label = torch.LongTensor([minibatch_label]).view(-1)\n",
        "\n",
        "        minibatch_data=minibatch_data.to(device)\n",
        "        minibatch_label=minibatch_label.to(device)\n",
        "        \n",
        "        h=h.detach()\n",
        "        c=c.detach()\n",
        "        h=h.requires_grad_()\n",
        "        c=c.requires_grad_()\n",
        "                            \n",
        "        scores = net( minibatch_data, h , c )\n",
        "\n",
        "        loss = criterion(  scores ,  minibatch_label )\n",
        "        \n",
        "        loss.backward()\n",
        "       \n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        num_batches += 1\n",
        "        \n",
        "    total_loss = running_loss/num_batches\n",
        "    elapsed = time.time()-start\n",
        "    \n",
        "    print('')\n",
        "    print('epoch=',epoch, '\\t time=', elapsed, '\\t exp(loss)=',  math.exp(total_loss))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        print('lr= ',param_group['lr'])\n",
        "        \n",
        "    eval_on_test_set()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch= 0 \t time= 801.7962701320648 \t exp(loss)= 2.703946934991306\n",
            "lr=  0.001\n",
            "test: exp(loss) =  7.4713609213588565\n",
            "correct 265 c_0 46 c_1 61 c_2 100 c_3 12 c_4 46\n",
            "Test accuracy:26.5%\n",
            "\n",
            "epoch= 1 \t time= 1617.4688956737518 \t exp(loss)= 2.5322300442396863\n",
            "lr=  0.001\n",
            "test: exp(loss) =  7.868999622455982\n",
            "correct 263 c_0 46 c_1 62 c_2 93 c_3 16 c_4 46\n",
            "Test accuracy:26.3%\n",
            "\n",
            "epoch= 2 \t time= 2428.161203622818 \t exp(loss)= 2.3722745986182665\n",
            "lr=  0.001\n",
            "test: exp(loss) =  8.151340626972232\n",
            "correct 268 c_0 53 c_1 65 c_2 90 c_3 16 c_4 44\n",
            "Test accuracy:26.8%\n",
            "\n",
            "epoch= 3 \t time= 3237.3708624839783 \t exp(loss)= 2.262513968211022\n",
            "lr=  0.001\n",
            "test: exp(loss) =  8.214737406514903\n",
            "correct 268 c_0 48 c_1 73 c_2 90 c_3 14 c_4 43\n",
            "Test accuracy:26.8%\n",
            "\n",
            "epoch= 4 \t time= 4045.487145423889 \t exp(loss)= 2.183380749826333\n",
            "lr=  0.001\n",
            "test: exp(loss) =  8.35510646154574\n",
            "correct 276 c_0 61 c_1 72 c_2 91 c_3 14 c_4 38\n",
            "Test accuracy:27.6%\n",
            "\n",
            "epoch= 5 \t time= 4853.626063108444 \t exp(loss)= 2.133085899399462\n",
            "lr=  0.001\n",
            "test: exp(loss) =  8.422243290463536\n",
            "correct 278 c_0 59 c_1 72 c_2 96 c_3 17 c_4 34\n",
            "Test accuracy:27.8%\n",
            "\n",
            "epoch= 6 \t time= 5662.685790538788 \t exp(loss)= 2.0402742818153516\n",
            "lr=  0.001\n",
            "test: exp(loss) =  8.862867006239512\n",
            "correct 285 c_0 53 c_1 80 c_2 98 c_3 16 c_4 38\n",
            "Test accuracy:28.5%\n",
            "\n",
            "epoch= 7 \t time= 6471.049778461456 \t exp(loss)= 1.9903708591480993\n",
            "lr=  0.001\n",
            "test: exp(loss) =  8.875637931240213\n",
            "correct 283 c_0 48 c_1 89 c_2 98 c_3 18 c_4 30\n",
            "Test accuracy:28.3%\n",
            "\n",
            "epoch= 8 \t time= 7279.208766460419 \t exp(loss)= 1.952176751770262\n",
            "lr=  0.001\n",
            "test: exp(loss) =  9.200256168045701\n",
            "correct 278 c_0 50 c_1 85 c_2 96 c_3 21 c_4 26\n",
            "Test accuracy:27.8%\n",
            "\n",
            "epoch= 9 \t time= 8087.942522764206 \t exp(loss)= 1.8980838077038673\n",
            "lr=  0.001\n",
            "test: exp(loss) =  9.38893595362742\n",
            "correct 272 c_0 46 c_1 89 c_2 91 c_3 23 c_4 23\n",
            "Test accuracy:27.2%\n",
            "\n",
            "epoch= 10 \t time= 8897.107684612274 \t exp(loss)= 1.8507934978332918\n",
            "lr=  0.001\n",
            "test: exp(loss) =  9.818748613797604\n",
            "correct 273 c_0 55 c_1 75 c_2 91 c_3 22 c_4 30\n",
            "Test accuracy:27.3%\n",
            "\n",
            "epoch= 11 \t time= 9707.544412136078 \t exp(loss)= 1.8083077570551525\n",
            "lr=  0.001\n",
            "test: exp(loss) =  9.40286054724737\n",
            "correct 287 c_0 41 c_1 97 c_2 104 c_3 19 c_4 26\n",
            "Test accuracy:28.7%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}